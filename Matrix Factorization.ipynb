{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cfa82534-6d19-4b9b-ba59-055fa603963d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f800f630-5070-41cc-b5f1-367d8c890d81",
   "metadata": {},
   "source": [
    "#### loading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0c8eda8-81ef-41e7-99db-dc322e4a248f",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"dataset/ml-latest-small/\"\n",
    "\n",
    "df = pd.read_csv(path + \"ratings.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b54292f-3862-4844-b829-d013ba7f8033",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964982703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964981247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964982224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>5.0</td>\n",
       "      <td>964983815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>5.0</td>\n",
       "      <td>964982931</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating  timestamp\n",
       "0       1        1     4.0  964982703\n",
       "1       1        3     4.0  964981247\n",
       "2       1        6     4.0  964982224\n",
       "3       1       47     5.0  964983815\n",
       "4       1       50     5.0  964982931"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f617b00c-b3be-40bb-ae4d-b5e1573be2da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "610"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.userId.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9775fd9c-eead-43f5-b3d9-aabc8d2cc5a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9724"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.movieId.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ea539238-52dd-46ff-b074-3a3e6fbdfa0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100836, 4)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b6fde25c-f022-4c65-a2f3-43ea65232cb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sparsity of dataset is 1.6999683055613624%\n"
     ]
    }
   ],
   "source": [
    "sparsity = len(df) / (df.userId.nunique() * df.movieId.nunique())\n",
    "\n",
    "print(f\"sparsity of dataset is {sparsity * 100}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b132150-7d37-4091-98d8-6db3c91c7875",
   "metadata": {},
   "source": [
    "#### matrix decomposition technique using SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b1e94726-8461-4f1d-8717-3d1ada6e5666",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25, RMSE Loss: 4.5050\n",
      "Epoch 2/25, RMSE Loss: 3.5213\n",
      "Epoch 3/25, RMSE Loss: 2.7860\n",
      "Epoch 4/25, RMSE Loss: 2.2924\n",
      "Epoch 5/25, RMSE Loss: 1.9893\n",
      "Epoch 6/25, RMSE Loss: 1.7896\n",
      "Epoch 7/25, RMSE Loss: 1.6446\n",
      "Epoch 8/25, RMSE Loss: 1.5354\n",
      "Epoch 9/25, RMSE Loss: 1.4472\n",
      "Epoch 10/25, RMSE Loss: 1.3745\n",
      "Epoch 11/25, RMSE Loss: 1.3137\n",
      "Epoch 12/25, RMSE Loss: 1.2627\n",
      "Epoch 13/25, RMSE Loss: 1.2188\n",
      "Epoch 14/25, RMSE Loss: 1.1803\n",
      "Epoch 15/25, RMSE Loss: 1.1440\n",
      "Epoch 16/25, RMSE Loss: 1.1145\n",
      "Epoch 17/25, RMSE Loss: 1.0854\n",
      "Epoch 18/25, RMSE Loss: 1.0613\n",
      "Epoch 19/25, RMSE Loss: 1.0379\n",
      "Epoch 20/25, RMSE Loss: 1.0163\n",
      "Epoch 21/25, RMSE Loss: 0.9972\n",
      "Epoch 22/25, RMSE Loss: 0.9789\n",
      "Epoch 23/25, RMSE Loss: 0.9639\n",
      "Epoch 24/25, RMSE Loss: 0.9477\n",
      "Epoch 25/25, RMSE Loss: 0.9337\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "\n",
    "class RatingDataset():\n",
    "    \n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "        self.users = torch.tensor(data['userId'].values - 1) \n",
    "\n",
    "        # Use LabelEncoder to transform non-contiguous movieId into contiguous integers\n",
    "        self.movie_encoder = LabelEncoder()\n",
    "        self.movies = torch.tensor(self.movie_encoder.fit_transform(data['movieId']), dtype=torch.long)\n",
    "\n",
    "        self.ratings = torch.tensor(data['rating'].values, dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.users[idx], self.movies[idx], self.ratings[idx]\n",
    "\n",
    "\n",
    "class MatrixFactorizationNN(nn.Module):\n",
    "    def __init__(self, num_users, num_items, num_factors):\n",
    "        super().__init__()\n",
    "\n",
    "        #Embedding layers for users and items\n",
    "        self.user_embedding = nn.Embedding(num_users, num_factors)  \n",
    "        self.item_embedding = nn.Embedding(num_items, num_factors)\n",
    "\n",
    "        #if we want a more complex model instead of a simple dot product, can consider:\n",
    "        # self.out = nn.Linear(num_factors, 1) \n",
    "\n",
    "    def forward(self, user, item):\n",
    "        # Get user and item embeddings\n",
    "        user_embedded = self.user_embedding(user)\n",
    "        item_embedded = self.item_embedding(item)\n",
    "\n",
    "        # Predicted rating is the dot product of the user and item embeddings\n",
    "        # Perform a element wise multiplication then sum them up together. \n",
    "        predicted_rating = (user_embedded * item_embedded).sum(1)\n",
    "        return predicted_rating\n",
    "\n",
    "\n",
    "dataset = RatingDataset(df)\n",
    "dataloader = DataLoader(dataset, batch_size=50, shuffle=True)\n",
    "\n",
    "num_users = df['userId'].nunique()\n",
    "num_items = df['movieId'].nunique()\n",
    "\n",
    "\n",
    "num_factors = 20  #latent factors\n",
    "model = MatrixFactorizationNN(num_users, num_items, num_factors)\n",
    "\n",
    "\n",
    "loss_function = nn.MSELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 25\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "\n",
    "    running_rmse = 0.0\n",
    "    for batch_users, batch_items, batch_ratings in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        predictions = model(batch_users, batch_items)\n",
    "        loss = loss_function(predictions, batch_ratings)\n",
    "        \n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_rmse += torch.sqrt(loss).item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, RMSE Loss: {running_rmse/len(dataloader):.4f}\")\n",
    "\n",
    "# # After training, we can now predict ratings using the trained model\n",
    "\n",
    "# model.eval()\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     predictions = model(input_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "040117d9-8448-4306-b0c6-a30596072bf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['_DataLoader__initialized', '_DataLoader__multiprocessing_context', '_IterableDataset_len_called', '__annotations__', '__class__', '__class_getitem__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__iter__', '__le__', '__len__', '__lt__', '__module__', '__ne__', '__new__', '__orig_bases__', '__parameters__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_auto_collation', '_dataset_kind', '_get_iterator', '_index_sampler', '_iterator', 'batch_sampler', 'batch_size', 'check_worker_number_rationality', 'collate_fn', 'dataset', 'drop_last', 'generator', 'multiprocessing_context', 'num_workers', 'persistent_workers', 'pin_memory', 'pin_memory_device', 'prefetch_factor', 'sampler', 'timeout', 'worker_init_fn']\n"
     ]
    }
   ],
   "source": [
    "print(dir(dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "323a6897-eac9-416c-9907-ca8f96181abb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__len__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', 'data', 'movie_encoder', 'movies', 'ratings', 'users']\n"
     ]
    }
   ],
   "source": [
    "print(dir(dataset))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
